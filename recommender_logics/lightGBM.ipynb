{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-13T14:22:45.860529Z",
     "start_time": "2025-10-13T14:22:44.422850Z"
    }
   },
   "source": "pip install lightgbm tqdm scikit-learn",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (from lightgbm) (2.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (from lightgbm) (1.16.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:22:49.135935Z",
     "start_time": "2025-10-13T14:22:47.863233Z"
    }
   },
   "cell_type": "code",
   "source": "pip install -U lightgbm",
   "id": "1b48b2cba7853f08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (from lightgbm) (2.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\yashw\\pycharmprojects\\pythonproject4\\.venv\\lib\\site-packages (from lightgbm) (1.16.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:29:28.524158Z",
     "start_time": "2025-10-13T14:22:56.871251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast, re, pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "#  Load LeetCode dataset\n",
    "df = pd.read_csv(\"../Data_Pipeline/preprocessed_data.csv\")\n",
    "\n",
    "def clean_title(text):\n",
    "    text = str(text).lower().strip()\n",
    "    text = re.sub(r'^\\d+\\.\\s*', '', text)\n",
    "    text = re.sub(r'[^a-z0-9\\s\\-]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def parse_similar(x):\n",
    "    try:\n",
    "        if isinstance(x, str):\n",
    "            lst = ast.literal_eval(x)\n",
    "            return [clean_title(i) for i in lst]\n",
    "        return []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "df['clean_title'] = df['title'].apply(clean_title)\n",
    "df['ground_truth'] = df['similar_questions'].apply(parse_similar)\n",
    "\n",
    "# ---- Load precomputed embeddings (from your previous hybrid model) ----\n",
    "cache_path = Path(\"sbert_embeddings.pkl\")\n",
    "if cache_path.exists():\n",
    "    with open(cache_path, \"rb\") as f:\n",
    "        cache = pickle.load(f)\n",
    "    embeddings = np.array(cache[\"embeddings\"], dtype=np.float32)\n",
    "else:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    embeddings = model.encode(df['title'].tolist(), show_progress_bar=True, normalize_embeddings=True)\n",
    "    with open(cache_path, \"wb\") as f:\n",
    "        pickle.dump({\"model_name\": \"all-MiniLM-L6-v2\", \"embeddings\": embeddings}, f)\n",
    "\n",
    "# Recreate helper similarities (tag, difficulty, popularity)\n",
    "def to_tag_list(s):\n",
    "    if isinstance(s, str) and s.startswith('['):\n",
    "        try:\n",
    "            vals = ast.literal_eval(s)\n",
    "            return [str(v).lower().strip() for v in vals]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return [t.strip().lower() for t in str(s).split(',') if t.strip()]\n",
    "\n",
    "df['tag_list'] = df['topic_tags'].apply(to_tag_list)\n",
    "df['difficulty'] = df['difficulty'].fillna('Medium')\n",
    "\n",
    "N = len(df)\n",
    "\n",
    "# Tag Jaccard matrix\n",
    "tag_sims = np.zeros((N, N), dtype=np.float32)\n",
    "for i in tqdm(range(N), desc=\"Tag similarity\"):\n",
    "    tags_i = set(df.iloc[i]['tag_list'])\n",
    "    for j in range(i+1, N):\n",
    "        tags_j = set(df.iloc[j]['tag_list'])\n",
    "        if not tags_i or not tags_j:\n",
    "            continue\n",
    "        inter = len(tags_i & tags_j)\n",
    "        uni = len(tags_i | tags_j)\n",
    "        if uni:\n",
    "            val = inter / uni\n",
    "            tag_sims[i,j] = tag_sims[j,i] = val\n",
    "\n",
    "# Difficulty matrix\n",
    "ladder = {\"easy\":0, \"medium\":1, \"hard\":2}\n",
    "diff_vals = df['difficulty'].str.lower().map(ladder).fillna(1).to_numpy(dtype=np.int8)\n",
    "diff_sims = np.ones((N, N), dtype=np.float32)\n",
    "for i in range(N):\n",
    "    for j in range(i+1, N):\n",
    "        d = abs(diff_vals[i]-diff_vals[j])\n",
    "        s = 1.0 if d==0 else 0.7 if d==1 else 0.4\n",
    "        diff_sims[i,j] = diff_sims[j,i] = s\n",
    "\n",
    "# Popularity normalization\n",
    "def minmax(x):\n",
    "    x = x.fillna(0)\n",
    "    rng = x.max() - x.min()\n",
    "    return (x - x.min())/rng if rng != 0 else x*0\n",
    "\n",
    "acc = minmax(df['acceptance']) if 'acceptance' in df else 0\n",
    "likes = minmax(df['likes']) if 'likes' in df else 0\n",
    "subs  = minmax(df['submission']) if 'submission' in df else 0\n",
    "popularity_score = (0.3*acc + 0.5*likes + 0.2*subs).fillna(0).to_numpy(dtype=np.float32)\n",
    "\n",
    "print(\"Setup complete: df, embeddings, tag_sims, diff_sims, popularity_score loaded.\")"
   ],
   "id": "8090f0f507cbe25c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashw\\PycharmProjects\\PythonProject4\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 116/116 [00:11<00:00, 10.21it/s]\n",
      "Tag similarity: 100%|██████████| 3706/3706 [06:01<00:00, 10.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete: df, embeddings, tag_sims, diff_sims, popularity_score loaded.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:30:42.901812Z",
     "start_time": "2025-10-13T14:30:32.864409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# FAST LIGHTGBM PAIRWISE RECOMMENDER\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TRAINING DATA GENERATION\n",
    "print(\"Generating positive & negative pairs (vectorized)...\")\n",
    "\n",
    "positive_rows = []\n",
    "negative_rows = []\n",
    "\n",
    "# Generate positive and negative pairs more efficiently\n",
    "for i in tqdm(range(len(df))):\n",
    "    gt = df.loc[i, 'ground_truth']\n",
    "    if not gt:\n",
    "        continue\n",
    "    # positive pairs\n",
    "    pos_idx = []\n",
    "    for title in gt:\n",
    "        j_match = df.index[df['clean_title'] == title].tolist()\n",
    "        if j_match:\n",
    "            pos_idx.append(j_match[0])\n",
    "    if not pos_idx:\n",
    "        continue\n",
    "\n",
    "    # compute positives\n",
    "    pos_emb = np.dot(embeddings[i], embeddings[pos_idx].T)\n",
    "    pos_tag = tag_sims[i, pos_idx]\n",
    "    pos_diff = diff_sims[i, pos_idx]\n",
    "    pos_pop = np.abs(popularity_score[i] - popularity_score[pos_idx])\n",
    "    pos_feats = np.stack([pos_emb, pos_tag, pos_diff, pos_pop], axis=1)\n",
    "    positive_rows.append(pos_feats)\n",
    "\n",
    "    # negative samples (5x random)\n",
    "    rand_idx = np.random.choice(len(df), size=min(5*len(pos_idx), len(df)), replace=False)\n",
    "    rand_idx = rand_idx[rand_idx != i]\n",
    "    neg_emb = np.dot(embeddings[i], embeddings[rand_idx].T)\n",
    "    neg_tag = tag_sims[i, rand_idx]\n",
    "    neg_diff = diff_sims[i, rand_idx]\n",
    "    neg_pop = np.abs(popularity_score[i] - popularity_score[rand_idx])\n",
    "    neg_feats = np.stack([neg_emb, neg_tag, neg_diff, neg_pop], axis=1)\n",
    "    negative_rows.append(neg_feats)\n",
    "\n",
    "X_pos = np.vstack(positive_rows)\n",
    "X_neg = np.vstack(negative_rows)\n",
    "y_pos = np.ones(len(X_pos))\n",
    "y_neg = np.zeros(len(X_neg))\n",
    "\n",
    "X = np.vstack([X_pos, X_neg])\n",
    "y = np.concatenate([y_pos, y_neg])\n",
    "\n",
    "print(f\"Training samples: {len(X)}, Positives: {int(sum(y))}, Negatives: {len(y)-int(sum(y))}\")\n",
    "\n",
    "#  TRAIN LIGHTGBM\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=200,\n",
    "    valid_sets=[train_data, val_data]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nFeature importances:\")\n",
    "for name, importance in zip([\"sim_emb\", \"sim_tag\", \"sim_diff\", \"pop_diff\"], model.feature_importance()):\n",
    "    print(f\"{name:10s} -> {importance}\")\n",
    "\n",
    "# RECOMMEND FUNCTION\n",
    "def rec_lightgbm_fast(i, k=10):\n",
    "    emb_sims = np.dot(embeddings[i], embeddings.T)\n",
    "    tag_vals = tag_sims[i]\n",
    "    diff_vals = diff_sims[i]\n",
    "    pop_diffs = np.abs(popularity_score[i] - popularity_score)\n",
    "    feats = np.stack([emb_sims, tag_vals, diff_vals, pop_diffs], axis=1)\n",
    "    scores = model.predict(feats)\n",
    "    scores[i] = -1e9  # exclude self\n",
    "    top_idx = np.argsort(scores)[-k:][::-1]\n",
    "    return [df.iloc[j]['clean_title'] for j in top_idx]\n",
    "\n",
    "#EVALUATION\n",
    "def precision_recall_ndcg(k=10, limit=300):\n",
    "    P,R,N = [],[],[]\n",
    "    for i in tqdm(range(min(limit, len(df)))):\n",
    "        gt = df.loc[i, 'ground_truth']\n",
    "        if not gt:\n",
    "            continue\n",
    "        preds = rec_lightgbm_fast(i, k)\n",
    "        hits = len(set(preds) & set(gt))\n",
    "        p = hits / k\n",
    "        r = hits / len(gt)\n",
    "        rel = [1 if x in gt else 0 for x in preds[:k]]\n",
    "        dcg = sum(r_ / np.log2(idx+2) for idx, r_ in enumerate(rel))\n",
    "        idcg = sum(sorted(rel, reverse=True)[i]/np.log2(i+2) for i in range(len(rel)))\n",
    "        ndcg = dcg/idcg if idcg>0 else 0\n",
    "        P.append(p); R.append(r); N.append(ndcg)\n",
    "    return np.mean(P), np.mean(R), np.mean(N)\n",
    "\n",
    "print(\"\\nEvaluating LightGBM model on 300 problems...\")\n",
    "P, R, N = precision_recall_ndcg(k=10, limit=300)\n",
    "print(f\"\\nLightGBM → Precision@10={P:.4f}, Recall@10={R:.4f}, NDCG@10={N:.4f}\")\n"
   ],
   "id": "c1c772572295cf9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating positive & negative pairs (vectorized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3706/3706 [00:03<00:00, 940.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 30720, Positives: 5121, Negatives: 25599\n",
      "\n",
      "Feature importances:\n",
      "sim_emb    -> 2373\n",
      "sim_tag    -> 1027\n",
      "sim_diff   -> 371\n",
      "pop_diff   -> 2229\n",
      "\n",
      "Evaluating LightGBM model on 300 problems...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 72.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM → Precision@10=0.1407, Recall@10=0.4554, NDCG@10=0.6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:35:46.426912Z",
     "start_time": "2025-10-13T14:35:46.398293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"../models/lightgbm_model.pkl\", \"wb\"))\n",
    "print(\" Model saved successfully \")\n"
   ],
   "id": "e52f4ae9a9a3e3a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved successfully \n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
